{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Level 5 Data Engineer\n",
        "## Module 3 Topic 9\n"
      ],
      "metadata": {
        "id": "J1UMcMhr3Qpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pip Installs"
      ],
      "metadata": {
        "id": "z3hcHyylolnW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX8mvJuhoVmd"
      },
      "outputs": [],
      "source": [
        "!pip install pandasql\n",
        "!pip install sqlalchemy==1.4.46\n",
        "!pip install sweetviz\n",
        "!pip install lazypredict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library Imports"
      ],
      "metadata": {
        "id": "hha9ZqYBoqK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandasql import sqldf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import sweetviz as sv\n",
        "import os\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "dyHVo0xmosry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# font size globally defined\n",
        "font = {'family' : 'normal',\n",
        "'weight' : 'bold',\n",
        "'size' : 14}\n",
        "\n",
        "matplotlib.rc('font', **font)"
      ],
      "metadata": {
        "id": "RxlBAEdFM1m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "data_path = kagglehub.dataset_download(\"uciml/default-of-credit-card-clients-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", data_path)"
      ],
      "metadata": {
        "id": "3xmixlUcwQeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(data_path)"
      ],
      "metadata": {
        "id": "jFkoaRluwzoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load our data\n",
        "data = pd.read_csv(os.path.join(data_path, 'UCI_Credit_Card.csv'))\n",
        "data = data[['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE',\n",
        "             'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
        "             'default.payment.next.month']]\n",
        "data.rename(columns={\n",
        "    'ID':'CLIENT_ID',\n",
        "    'default.payment.next.month':'DEFAULT'}, inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "nj9uBka6pXHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data dictionary\n",
        "\n",
        "- **CLIENT_ID**: Unique identifier for each client.\n",
        "- **LIMIT_BAL**: The total credit amount (in pound sterling) granted to the client, including both individual and supplementary credit.\n",
        "- **SEX**: (1 = male, 2 = female).\n",
        "- **EDUCATION**: Client's highest level of education (1 = university, 2 = college, 3 = apprenticeship, 4 = unknown, 5 = GCSE, 6 = unknown).\n",
        "- **MARRIAGE**: Client's marital status (1 = married, 2 = single, 3 = other).\n",
        "- **AGE**: Client's age in years.\n",
        "- **PAY_0**: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, â€¦ 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
        "- **PAY_2**: Repayment status in August 2005, with the same scale as PAY_0.\n",
        "- **PAY_3**: Repayment status in July 2005, with the same scale as PAY_0.\n",
        "- **PAY_4**: Repayment status in June 2005, with the same scale as PAY_0.\n",
        "- **PAY_5**: Repayment status in May 2005, with the same scale as PAY_0.\n",
        "- **PAY_6**: Repayment status in April 2005, with the same scale as PAY_0.\n",
        "- **Default**: Credit card default states (0=No, 1=Yes)."
      ],
      "metadata": {
        "id": "bAJDPrJgq4It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# value counts of default\n",
        "plt.style.use('fivethirtyeight')\n",
        "logging.getLogger('matplotlib.font_manager').setLevel(level=logging.CRITICAL)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,3))\n",
        "\n",
        "data['DEFAULT'].value_counts(normalize=True).plot(kind='barh', ax=ax)\n",
        "print(data['DEFAULT'].value_counts(normalize=True) *100)\n",
        "\n",
        "ax.set(xlabel='Proportion 0-1', ylabel='Default Label', title='Credit Card Default Distribution');"
      ],
      "metadata": {
        "id": "WzlwJ99VrWCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Profiling"
      ],
      "metadata": {
        "id": "vwM8cD4iotUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Report = sv.analyze(data)\n",
        "\n",
        "Report.show_notebook()"
      ],
      "metadata": {
        "id": "QWY-gnDtovEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Test Split"
      ],
      "metadata": {
        "id": "YgDld_HxowHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning up the data\n",
        "lower_names = []\n",
        "\n",
        "for column_name in data.columns:\n",
        "    lower_names.append(column_name.lower())\n",
        "\n",
        "data.columns = lower_names"
      ],
      "metadata": {
        "id": "Z_WjTp9KvK-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "iO3iziv9wlfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what is our distribution for the target variable in the original data?\n",
        "\n",
        "data['default'].value_counts(normalize=True) * 100"
      ],
      "metadata": {
        "id": "8e9vd4ckwvVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train - test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(data, test_size=0.3,\n",
        "                                     random_state=1234,\n",
        "                                     stratify=data['default'])\n",
        "\n",
        "print(df_train['default'].value_counts(normalize=True))\n",
        "print(df_test['default'].value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "jJRgXinjozsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what did we do?\n",
        "print(data.shape)\n",
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "metadata": {
        "id": "eLIofqDZx5dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "7MZXuImso1Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['default'].mean()"
      ],
      "metadata": {
        "id": "Dqk0QVY2o25g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering / Extraction\n",
        "\n",
        "It is the formal process of taking raw data and creating new columns and measures by combining existing columns or applying formulas on them.\n",
        "\n"
      ],
      "metadata": {
        "id": "SHOHLN2x7zIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to add together positive delay values\n",
        "def sum_positive(series):\n",
        "    filter_condition = series > 0\n",
        "    return series[filter_condition].sum()\n"
      ],
      "metadata": {
        "id": "Kuftmhml2NNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "hLGAaVu_3E2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate features for df train\n",
        "\n",
        "df_train['avg_delay'] = (df_train[['pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']]\n",
        "                         .apply(lambda x: x[x > 0].mean(), axis=1))\n",
        "\n",
        "\n",
        "df_train['avg_delay'].fillna(0, inplace=True)\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "7Z2xt5cC2nlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create extra information - df test\n",
        "df_test['avg_delay'] = (df_test[['pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']]\n",
        "                         .apply(lambda x: x[x > 0].mean(), axis=1))\n",
        "\n",
        "df_test['avg_delay'].fillna(0, inplace=True)\n",
        "\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "ikjB-K2z1Wux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total payment delay\n",
        "df_train['total_delay'] = (df_train[['pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']]\n",
        "                         .apply(sum_positive, axis=1))\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "ebdF5Ny8434M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature    | Value  | Description                                              |\n",
        "|------------|--------|----------------------------------------------------------|\n",
        "| CLIENT_ID  | 7188   | Unique identifier for the client                         |\n",
        "| LIMIT_BAL  | 20000  | Total credit amount (in NT dollars)                      |\n",
        "| SEX        | 1      | Gender (1 = male)                                        |\n",
        "| EDUCATION  | 2      | Highest level of education (2 = university)              |\n",
        "| MARRIAGE   | 2      | Marital status (2 = single)                              |\n",
        "| AGE        | 25     | Age in years                                             |\n",
        "| PAY_0      | 1      | Repayment status in September 2005 (1 month delayed)     |\n",
        "| PAY_2      | 2      | Repayment status in August 2005 (2 months delayed)       |\n",
        "| PAY_3      | 2      | Repayment status in July 2005 (2 months delayed)         |\n",
        "| PAY_4      | 2      | Repayment status in June 2005 (2 months delayed)         |\n",
        "| PAY_5      | 2      | Repayment status in May 2005 (2 months delayed)          |\n",
        "| PAY_6      | 0      | Repayment status in April 2005 (revolving credit or no transactions) |\n",
        "| DEFAULT    | 0      | Credit card default status (1 = Yes)                     |\n",
        "| avg_delay  | 1.80   | Average delay in payments across all months              |\n",
        "| total_delay| 9      | Total delay in payments across all months                |\n"
      ],
      "metadata": {
        "id": "8RN0wHXG52q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# total delay with the test set\n",
        "df_test['total_delay'] = (df_test[['pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']]\n",
        "                         .apply(sum_positive, axis=1))\n",
        "\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "WgFr6ZaS5UY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas Groupby Function\n",
        "\n",
        "The Pandas `groupby` function is a powerful method used for grouping DataFrame rows based on the values of one or more columns. It enables you to perform various aggregation operations on the grouped data, such as computing the sum, mean, count, or other custom aggregation functions.\n",
        "\n",
        "### Syntax\n",
        "\n",
        "`DataFrame.groupby(by, axis, level, as_index, sort, group_keys, squeeze, observed)`\n",
        "\n",
        "- `by`: The column(s) to group by. Can be a single column, a list of columns, or a dictionary mapping columns to group names.\n",
        "- `axis`: The axis to group along, either 0 (default) for rows or 1 for columns.\n",
        "- `sort`: If `True` (default), the group keys will be sorted. If `False`, the group keys will not be sorted, which may improve performance.\n",
        "- `group_keys`: If `True` (default), the group keys will be included in the result. If `False`, the group keys will not be included.\n",
        "- `observed`: If `True`, only show observed values for categorical groupers. If `False` (default), show all values.\n",
        "\n",
        "### Basic Example\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
        "        'Value': [10, 20, 30, 40, 50, 60]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Group by Category\n",
        "grouped = df.groupby('Category')\n",
        "\n",
        "# Compute the sum of the Value column for each group\n",
        "result = grouped['Value'].sum()\n"
      ],
      "metadata": {
        "id": "QWdu4QjPAa4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hypothesis: customers who delay more often and over longer durations default more!\n",
        "agg_df1 = df_train.groupby('total_delay').agg(count=(\"total_delay\", \"size\"),\n",
        "                                    mean_target=(\"default\", \"mean\")).reset_index()\n",
        "\n",
        "agg_df1"
      ],
      "metadata": {
        "id": "HVpH76Dn5vrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualise\n",
        "plt.style.use('fivethirtyeight')\n",
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "\n",
        "# create secondary y-axis\n",
        "ax2 = ax.twinx()\n",
        "\n",
        "ax.bar(list(agg_df1['total_delay']), list(agg_df1[\"count\"]))\n",
        "ax2.plot(list(agg_df1['mean_target']), color='r', linewidth=3)\n",
        "\n",
        "ax.grid(False)"
      ],
      "metadata": {
        "id": "FW7UrOhB6w6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# average delay\n",
        "agg_df2 = df_train.groupby('avg_delay').agg(count=(\"avg_delay\", \"size\"),\n",
        "                                    mean_target=(\"default\", \"mean\")).reset_index()\n",
        "\n",
        "agg_df2.head()"
      ],
      "metadata": {
        "id": "25JExEH_9Jjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection - What do we include in our model?"
      ],
      "metadata": {
        "id": "GvtKhSiBKie2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what are the irrelevant columns?\n",
        "df_train.columns"
      ],
      "metadata": {
        "id": "x_9SSXlyF6ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let us look at a correlation matrix\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set(font_scale=0.8)\n",
        "\n",
        "correlation_matrix = df_train.drop('client_id', axis=1).corr()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "\n",
        "mask = np.zeros_like(correlation_matrix, dtype=bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "ax = sns.heatmap(correlation_matrix, mask=mask, ax=ax, cmap='YlGnBu', annot=True)"
      ],
      "metadata": {
        "id": "F8su_UAGKnp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building - Predictive Analytics"
      ],
      "metadata": {
        "id": "Ug-r0boOBD_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1) Drop all the irrelevant columns and split X_train, X_test\n",
        "\n",
        "Step 2) Select the right model and import it and use it to train\n",
        "\n",
        "Step 3) We train on the training sets & test on the X_test (generating y_pred - basically running the model)\n",
        "\n",
        "Step 4) We evaluate the performance of our y_pred against the true values of y_test (i.e., generate the accuracy and loss metrices)\n",
        "\n",
        "Step 5) Model diagnostics - creating reports on the model performance\n",
        "\n",
        "Step 6) Conclusion model is not good enough and we need to fine-tune / or model is good enough and we can publish!"
      ],
      "metadata": {
        "id": "Mbr-htKwBH2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what is the right model to pick?\n",
        "df_train['default'].unique()"
      ],
      "metadata": {
        "id": "xUuayqVFAXob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Our Prediction Problem is a Classification Task! Binary Classification**"
      ],
      "metadata": {
        "id": "oXu-TjMsGi1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what is the effect of limit_balance\n",
        "# are customer with high limit balance less likely to default?\n",
        "\n",
        "# Distribution of LIMIT_BAL\n",
        "import matplotlib.ticker as mticker\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sns.histplot(data=df_train, x='limit_bal', kde=True, hue=\"default\",\n",
        "             bins=20, multiple=\"dodge\", ax=ax, shrink=0.8)\n",
        "\n",
        "# Format x-axis with dollar sign and \"k\" for thousands\n",
        "formatter = mticker.FuncFormatter(lambda x, pos: f\"${int(x/1000)}k\")\n",
        "ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "# Set the title\n",
        "ax.set_title('Credit Limit Distribution')\n",
        "\n",
        "# Add arrow annotation\n",
        "arrow_props = dict(facecolor='steelblue')\n",
        "ax.annotate('Non-defaulting customers have a higher credit limit on average',\n",
        "             xy=(220000, 2000), xytext=(400000, 2800),\n",
        "             fontsize=12, color='dodgerblue', arrowprops=arrow_props)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zWqJrxbzQyn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.columns)"
      ],
      "metadata": {
        "id": "Ln-8xoFPRiDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the irrelevant columns\n",
        "# marriage, education, client_id, age, age_group\n",
        "cols_to_drop = ['client_id', 'sex', 'education', 'marriage', 'age']\n",
        "\n",
        "df_train.drop(cols_to_drop, axis=1, inplace=True)\n",
        "df_test.drop(cols_to_drop, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "pP9LdV16JQAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(20)"
      ],
      "metadata": {
        "id": "Qbicus_0YEKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data further into X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train = df_train.drop('default', axis=1)\n",
        "X_test = df_test.drop('default', axis=1)\n",
        "\n",
        "y_train = df_train['default']\n",
        "y_test = df_test['default']"
      ],
      "metadata": {
        "id": "P-zdBDFhR8k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can inspect the arrays\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "wRUlKInBeXJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what is X_train?\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "VrP_Yxfqeg0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# binary balance helper\n",
        "\n",
        "def binary_balance(target_train, target_test, plot_dist=True):\n",
        "    '''\n",
        "    Plot distribution of binary target\n",
        "    '''\n",
        "    if plot_dist:\n",
        "        fig, axs = plt.subplots(ncols=2, figsize=(17, 5), sharey=True)\n",
        "        target_train.value_counts(normalize = True).plot(kind=\"bar\", ax=axs[0])\n",
        "        axs[0].set_title(\"Training Set Distribution\")\n",
        "        axs[0].set_xticklabels(target_train.unique(),rotation=70)\n",
        "        target_test.value_counts(normalize=True).plot(kind=\"bar\", ax=axs[1])\n",
        "        axs[1].set_title(\"Test Set Distribution\")\n",
        "        axs[1].set_xticklabels(target_test.unique(), rotation=70)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "BC_784E5epm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare the distribution of the two arrays\n",
        "binary_balance(y_train, y_test)"
      ],
      "metadata": {
        "id": "_lxwTIcCe1S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "# load the lazyclassifier engine - specify settings\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True,\n",
        "                     custom_metric=None, predictions=True)\n",
        "\n",
        "# run the lazyclassifier engine\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "models"
      ],
      "metadata": {
        "id": "KenjcpBye750"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for better readability we can sort the results\n",
        "models.sort_values(by=['Accuracy', 'F1 Score'], axis=0, ascending=False)"
      ],
      "metadata": {
        "id": "_9kQLvPGgWeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run a random forest classifier algorithm!\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import *\n",
        "\n",
        "# step 1: initialise / load the model\n",
        "classifier = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=4)\n",
        "\n",
        "# step 2: train the model on X_train, y_train\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# step 3: generate y_pred - using .predict()\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# step 4: evaluate the accuracy and compare y_pred to the true values y_test\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Balanced Accuracy:\", balanced_accuracy)\n",
        "print(\"F1-score: \", f1)"
      ],
      "metadata": {
        "id": "wB1MGtqBg3GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why are the results less than ideal? Potential Solutions?\n",
        "\n",
        "1) Get more data: we haven't actually used all the features available in the dataset\n",
        "\n",
        "2) Hyperparameter tuning and experimenting with different algorithms\n",
        "\n",
        "3) Speak to domain experts to improve our feature engineering approach.\n"
      ],
      "metadata": {
        "id": "6AlGtLSjluj4"
      }
    }
  ]
}