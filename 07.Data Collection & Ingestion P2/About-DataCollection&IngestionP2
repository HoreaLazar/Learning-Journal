## Module 7 - Topic 1 - Event-driven architectures (EDA) fundamentals

# Event-Driven Architectures (EDA):

EDA allows for asynchronous communication between system components, enhancing responsiveness and scalability.

Key components include events, event producers, event consumers, and event brokers.


# The Pub-Sub Model:

In the Pub-Sub model, publishers emit messages to specific topics, and subscribers receive messages based on their interests.

This model decouples producers and consumers, improving system flexibility and scalability.


# Apache Kafka:

Kafka is a distributed event streaming platform used for high-throughput, fault-tolerant data streams.

Core concepts include topics, partitions, producers, consumers, consumer groups, and Kafka clusters.

Kafka ensures data consistency through replication and treats each partition as an immutable log.


# Collaboration and Presentation Skills

Effective collaboration involves clear communication, defined roles, and regular meetings.

Crafting captivating presentations requires a clear objective, logical flow, and engaging storytelling techniques.

Tailor your message to the audience, use real-world examples, and incorporate visual aids to enhance understanding.


# Examples of Real-World Applications

Banking: Real-time fraud detection using Kafka to process transactions instantly.

Human resources: Seamless propagation of employee data changes across systems.

Charities: Monitoring donation activities to boost donor engagement.

Nature conservation: Tracking wildlife movements in real-time for proactive conservation efforts.
____________________________________________________________________________________________________

## Module 7 Topic 4 - Monitoring an ingestion service and anomaly detection techniques

Prometheus and Grafana are essential tools for monitoring data ingestion pipelines, providing metrics collection, alerting, and visualisation to ensure system reliability and performance.

Forecasting techniques like ARIMA and SARIMAX are crucial for predicting future data ingestion rates, allowing for effective capacity planning and preventing system overloads.

Anomaly detection methods, such as Isolation Forest and Seasonal Hybrid ESD, are vital for identifying unusual patterns in data streams, helping to detect system failures, security breaches, and operational issues.

Integrating Prometheus Alertmanager with incident management platforms like PagerDuty enhances operational responsiveness by ensuring that critical incidents are promptly addressed and resolved.

Understanding and addressing common ingestion issues, such as consumer lag, broker failures, and message loss, is essential for maintaining robust and reliable data pipelines.

Exploring advanced anomaly detection methods and implementing comprehensive monitoring solutions like the Elastic Stack (ELK) can significantly enhance the ability to manage and analyse complex data systems.
